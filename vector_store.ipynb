{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05882bce",
   "metadata": {},
   "source": [
    "# Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679f6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b45435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from collections import defaultdict, namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9541e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parameters\n",
    "VECTOR_SIZE = 100\n",
    "WINDOW      = 5\n",
    "MIN_COUNT   = 5\n",
    "WORKERS     = 4\n",
    "MAX_WORDS_IN_BATCH = 10000\n",
    "#MAX_WORDS From https://github.com/piskvorky/gensim/blob/develop/gensim/models/word2vec_inner.pyx#L27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78484fb5",
   "metadata": {},
   "source": [
    "### CustomLineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c539367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from gensim import utils\n",
    "\n",
    "class CustomLineSentence:\n",
    "    def __init__(self, source):\n",
    "        self.source = source\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate through the lines in the source.\"\"\"\n",
    "        with utils.open(self.source, 'rb') as fin:\n",
    "            for line in itertools.islice(fin, None):\n",
    "                line = utils.to_unicode(line).split()\n",
    "                i = 0\n",
    "                while i < len(line):\n",
    "                    yield line[i: i + MAX_WORDS_IN_BATCH]\n",
    "                    i += MAX_WORDS_IN_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "407a4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the text8 corpus as a stream of sentences\n",
    "sentences = CustomLineSentence('data/text8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e66dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWord2Vec:\n",
    "     def __init__(self, sentences=None, vector_size=100, window=5, min_count=5, workers=3):\n",
    "\n",
    "          corpus_iterable = sentences\n",
    "\n",
    "          self.sentences = sentences\n",
    "          self.vector_size = vector_size\n",
    "          self.window = window\n",
    "          self.min_count = min_count\n",
    "          self.workers = workers\n",
    "\n",
    "          # from Word2Vec parameters\n",
    "          self.shrink_windows=True\n",
    "          self.compute_loss=False\n",
    "          self.sorted_vocab=1\n",
    "          self.null_word=0\n",
    "          self.epochs=5\n",
    "          self.hashfxn=hash\n",
    "          self.cbow_mean=1\n",
    "          self.ns_exponent=0.75\n",
    "          self.negayive=5\n",
    "          self.hs=0\n",
    "          self.sg=0\n",
    "          self.min_alpha=0.0001\n",
    "          self.seed=1\n",
    "          self.sample=0.001\n",
    "          self.alpha=0.025\n",
    "          \n",
    "          # normal init valuse\n",
    "          self.train_count = 0\n",
    "          self.total_train_time = 0\n",
    "          self.running_training_loss = 0\n",
    "          self.corpus_count = 0\n",
    "          self.corpus_total_words = 0\n",
    "\n",
    "          # Main part build vocab\n",
    "          self.build_vocab(corpus_iterable=corpus_iterable, corpus_file=None, trim_rule=None)\n",
    "\n",
    "\n",
    "     def scan_vocab(self, sentences=None, corpus_file=None):\n",
    "          \"\"\"Scan the corpus to determine the vocabulary size and word frequencies.\"\"\"\n",
    "          if corpus_file:\n",
    "               sentences = CustomLineSentence(corpus_file) # potentially this could be removed - TODO: test this later\n",
    "\n",
    "          sentence_no = -1\n",
    "          total_words = 0\n",
    "          vocab = defaultdict(int)\n",
    "\n",
    "          for sentence_no, sentence in enumerate(sentences):\n",
    "            for word in sentence:\n",
    "                vocab[word] += 1\n",
    "            total_words += len(sentence)\n",
    "\n",
    "          corpus_count = sentence_no + 1\n",
    "          self.raw_vocab = vocab\n",
    "\n",
    "          return total_words, corpus_count\n",
    "\n",
    "     def build_vocab(self, corpus_iterable, corpus_file=None, trim_rule=None, progress_per=10000):\n",
    "          total_words, corpus_count = self.scan_vocab(sentences=corpus_iterable, corpus_file=corpus_file)\n",
    "          print(f\"Total words: {total_words}, Corpus count: {corpus_count}\")\n",
    "          \n",
    "\n",
    "     def train():\n",
    "          pass\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b078238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 17005207, Corpus count: 1701\n"
     ]
    }
   ],
   "source": [
    "model = CustomWord2Vec(\n",
    "    sentences,\n",
    "    vector_size=VECTOR_SIZE,\n",
    "    window=WINDOW,\n",
    "    min_count=MIN_COUNT,\n",
    "    workers=WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b3080b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7531704306602478), ('prince', 0.7207016944885254), ('emperor', 0.7185539603233337), ('throne', 0.700005292892456), ('vii', 0.675726592540741), ('aragon', 0.6742899417877197), ('kings', 0.6729216575622559), ('viii', 0.6662270426750183), ('pope', 0.6596798300743103), ('judah', 0.654106855392456)]\n"
     ]
    }
   ],
   "source": [
    "# 3. Train Word2Vec\n",
    "model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=VECTOR_SIZE,\n",
    "    window=WINDOW,\n",
    "    min_count=MIN_COUNT,\n",
    "    workers=WORKERS\n",
    ")\n",
    "\n",
    "# 4. Save the trained model\n",
    "model.save('models/text8_w2v_100d.model')\n",
    "\n",
    "# 5. Quick sanity check\n",
    "print(model.wv.most_similar('king', topn=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

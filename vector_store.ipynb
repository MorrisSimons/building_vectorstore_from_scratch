{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05882bce",
   "metadata": {},
   "source": [
    "# Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "679f6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b45435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9541e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Parameters\n",
    "VECTOR_SIZE = 100\n",
    "WINDOW      = 5\n",
    "MIN_COUNT   = 5\n",
    "WORKERS     = 4\n",
    "MAX_WORDS_IN_BATCH = 1000\n",
    "#MAX_WORDS From https://github.com/piskvorky/gensim/blob/develop/gensim/models/word2vec_inner.pyx#L27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78484fb5",
   "metadata": {},
   "source": [
    "### CustomLineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c539367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from gensim import utils\n",
    "\n",
    "class CustomLineSentence:\n",
    "    def __init__(self, source, limit=None, max_sentence_length=10000):\n",
    "        self.source = source\n",
    "        self.limit = limit\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate through the lines in the source.\"\"\"\n",
    "        try:\n",
    "            self.source.seek(0)\n",
    "            for line in itertools.islice(self.source, self.limit):\n",
    "                line = utils.to_unicode(line).split()\n",
    "                i = 0\n",
    "                while i < len(line):\n",
    "                    yield line[i: i + self.max_sentence_length]\n",
    "                    i += self.max_sentence_length\n",
    "        except AttributeError:\n",
    "            with utils.open(self.source, 'rb') as fin:\n",
    "                for line in itertools.islice(fin, self.limit):\n",
    "                    line = utils.to_unicode(line).split()\n",
    "                    i = 0\n",
    "                    while i < len(line):\n",
    "                        yield line[i: i + self.max_sentence_length]\n",
    "                        i += self.max_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3080b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the text8 corpus as a stream of sentences\n",
    "sentences = LineSentence('data/text8')\n",
    "\n",
    "# 3. Train Word2Vec\n",
    "model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=VECTOR_SIZE,\n",
    "    window=WINDOW,\n",
    "    min_count=MIN_COUNT,\n",
    "    workers=WORKERS\n",
    ")\n",
    "\n",
    "# 4. Save the trained model\n",
    "model.save('models/text8_w2v_100d.model')\n",
    "\n",
    "# 5. Quick sanity check\n",
    "print(model.wv.most_similar('king', topn=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
